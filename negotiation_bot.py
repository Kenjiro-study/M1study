# %% [markdown]
# # Llama3 äº¤æ¸‰ãƒœãƒƒãƒˆ (Dockerã‚³ãƒ³ãƒ†ãƒŠ & VS Codeã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–å®Ÿè¡Œç”¨)
#
# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€`#%%` ã§åŒºåˆ‡ã‚‰ã‚ŒãŸã‚»ãƒ«ã‚’VS Codeã®ã€Œã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã€ã§
# ä¸€ã¤ãšã¤å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚

# %%
# =============================================
# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# =============================================
import torch # æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª(GPUè¨ˆç®—ã«å¿…è¦)
import transformers # Hugging faceã®AIãƒ¢ãƒ‡ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import warnings
import os # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«ä½¿ç”¨
from getpass import getpass # ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ã«ä½¿ç”¨

warnings.filterwarnings("ignore") # è­¦å‘Šè¡¨ç¤ºã‚’ç„¡ãã™(â€» ãƒ‡ãƒãƒƒã‚°ã™ã‚‹ã¨ãã¯å¤–ã—ã¦ã¡ã‚ƒã‚“ã¨è­¦å‘Šã‚’è¦‹ã‚‹ã‚ˆã†ã«ï¼)
print("âœ… step1: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


# %%
# =============================================
# ã‚¹ãƒ†ãƒƒãƒ—2: Hugging Faceã¸ã®ãƒ­ã‚°ã‚¤ãƒ³
# =============================================
if 'HUGGING_FACE_HUB_TOKEN' not in os.environ:
    print("Hugging Faceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:")
    hf_token = getpass() # getpassã§æ©Ÿå¯†æƒ…å ±ã®å…¥åŠ›è¦æ±‚
    os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token # Hugging Faceã®ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ ¼ç´ã™ã‚‹ç’°å¢ƒå¤‰æ•°HUGGING_FACE_HUB_TOKENã«å…¥åŠ›ã•ã‚ŒãŸã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ ¼ç´
print("ğŸ”‘ step2: ãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸã€‚")


# %%
# =============================================
# ã‚¹ãƒ†ãƒƒãƒ—3: äº¤æ¸‰ãƒœãƒƒãƒˆã‚¯ãƒ©ã‚¹ã®å®šç¾©
# =============================================
class NegotiationBot:
    # ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿(botãŒä½œã‚‰ã‚Œã‚‹æ™‚ã«æœ€åˆã«å®Ÿè¡Œã•ã‚Œã‚‹éƒ¨åˆ†)
    def __init__(self, model_id: str = "meta-llama/Llama-3.1-8B-Instruct"):
        self.model_id = model_id # ãƒ¢ãƒ‡ãƒ«ã®åå‰
        self.pipeline = None # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
        self.messages = [] # å¯¾è©±å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
        print(f"ãƒœãƒƒãƒˆã®è¨­è¨ˆå›³ï¼ˆã‚¯ãƒ©ã‚¹ï¼‰ã‚’æº–å‚™ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ID: {self.model_id}")

    def load_model(self):
        if self.pipeline:
            print("ãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã™ã€‚") # ã‚‚ã—ã™ã§ã«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå­˜åœ¨ã—ã¦ã„ã‚Œã°ãƒ¢ãƒ‡ãƒ«ãŒã™ã§ã«ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã®ã§ã‚¹ã‚­ãƒƒãƒ—
            return
            
        print(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™: {self.model_id}...")
        print("ï¼ˆã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰")
        try:
            tokenizer = AutoTokenizer.from_pretrained(self.model_id) # æŒ‡å®šãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰
            model = AutoModelForCausalLM.from_pretrained(
                self.model_id,
                torch_dtype=torch.bfloat16, # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’bfloat16ã¨ã„ã†GPUãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„ã—ã¤ã¤, æ¨è«–é€Ÿåº¦ã‚’æ’å¸¸åŒ–ã•ã›ã‚‹æœ€é©åŒ–æ‰‹æ³•ã®ã‚‚ã®ã«æŒ‡å®š
                device_map="auto", # ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ãƒ‡ãƒã‚¤ã‚¹(GPU or CPU)ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã‹è‡ªå‹•ã§åˆ¤æ–­ã—ã¦ãã‚Œã‚‹
            )
            # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç”Ÿæˆ
            self.pipeline = pipeline(
                "text-generation", model=model, tokenizer=tokenizer
            )
            print("âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒæˆåŠŸã—ã¾ã—ãŸã€‚")
            # GPUã®åˆ©ç”¨ç¢ºèª
            if torch.cuda.is_available():
                print(f"âœ… GPUãŒåˆ©ç”¨å¯èƒ½ã§ã™: {torch.cuda.get_device_name(0)}")
            else:
                print("âš ï¸ GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã§å®Ÿè¡Œã—ã¾ã™ï¼ˆéå¸¸ã«é…ããªã‚Šã¾ã™ï¼‰ã€‚")
        # ã‚¨ãƒ©ãƒ¼å‡¦ç†
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            raise

    def set_scenario(self, item_description: str, seller_price: int, seller_target_price: int):
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        # ã“ã“ã§botãŒã©ã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã†ã‹, ã©ã®ã‚ˆã†ã«äº¤æ¸‰ã‚’é€²ã‚ã‚‹ã‹ã‚’æŒ‡ç¤ºã™ã‚‹
        system_prompt = f"""
ã‚ãªãŸã¯ä¾¡æ ¼äº¤æ¸‰ã‚’è¡Œã†ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚å½¹å‰²ã¯ã€Œå£²ã‚Šæ‰‹ã€ã§ã™ã€‚
ã“ã‚Œã‹ã‚‰ã€Œè²·ã„æ‰‹ã€ã¨å•†å“ã®ä¾¡æ ¼ã«ã¤ã„ã¦äº¤æ¸‰ã—ã¾ã™ã€‚ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‹ã¤ã€ã—ã‹ã—å‹å¥½çš„ãªæ…‹åº¦ã§äº¤æ¸‰ã‚’é€²ã‚ã¦ãã ã•ã„ã€‚

**äº¤æ¸‰ã‚·ãƒŠãƒªã‚ª:**
- **å•†å“:** {item_description}
- **ã‚ãªãŸã®æç¤ºä¾¡æ ¼:** ${seller_price}
- **ã‚ãªãŸã®ç›®æ¨™:** ã§ãã‚‹ã ã‘ ${seller_target_price} ã«è¿‘ã„ä¾¡æ ¼ã§å£²ã‚‹ã“ã¨ã€‚

ã‚ãªãŸã¯è²·ã„æ‰‹ã®ææ¡ˆã‚’æ¤œè¨ã—ã€ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚ªãƒ•ã‚¡ãƒ¼ã‚’æç¤ºã—ãŸã‚Šã€å•†å“ã®ä¾¡å€¤ã‚’èª¬æ˜ã—ãŸã‚Šã—ã¦ã€æœ‰åˆ©ãªä¾¡æ ¼ã§ã®åˆæ„ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚
è¿”ç­”ã¯å£²ã‚Šæ‰‹ã¨ã—ã¦ã€è‡ªç„¶ãªä¼šè©±å½¢å¼ã§ç°¡æ½”ã«ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
"""
        self.messages = [{"role": "system", "content": system_prompt.strip()}] # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®åˆæœŸåŒ–
        print("\n--- ã‚·ãƒŠãƒªã‚ªè¨­å®šå®Œäº† ---")
        print(f"å•†å“: {item_description}")
        print(f"å£²ã‚Šæ‰‹ã®æç¤ºä¾¡æ ¼: ${seller_price}")
        print("---------------------\n")

    def talk(self, user_input: str) -> str:
        # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ç¢ºèª
        if not self.pipeline:
            return "ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ `load_model()` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        
        # user_inputã¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿ç®¡
        self.messages.append({"role": "user", "content": user_input})

        # ã“ã‚Œã¾ã§ã®å¯¾è©±å±¥æ­´ã‚’å…ƒã«ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã§ãã‚‹å½¢å¼ã®å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
        # ã“ã‚Œã«ã‚ˆã‚Šã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ, ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•, botã®å¿œç­”ãªã©ãŒçµåˆã•ã‚Œã¦, ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä½œæˆã•ã‚Œã‚‹
        prompt = self.pipeline.tokenizer.apply_chat_template(
            self.messages, tokenize=False, add_generation_prompt=True
        )

        # ãƒ¢ãƒ‡ãƒ«ãŒãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’ã©ã“ã§æ­¢ã‚ã‚‹ã‹ã‚’æŒ‡ç¤ºã™ã‚‹çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³(terminators)ã®è¨­å®š
        terminators = [
            self.pipeline.tokenizer.eos_token_id, # ä¸€èˆ¬çš„ãªãƒ¢ãƒ‡ãƒ«ã§ä½¿ç”¨ã•ã‚Œã‚‹ã€Œend-of-sequenceã€ï¼ˆç³»åˆ—ã®çµ‚ã‚ã‚Šï¼‰ãƒˆãƒ¼ã‚¯ãƒ³ã®ID
            self.pipeline.tokenizer.convert_tokens_to_ids("<|eot_id|>") # Llama3ã§ä½¿ç”¨ã•ã‚Œã‚‹ã€Œend of turnã€ï¼ˆç™ºè©±ã®çµ‚ã‚ã‚Šï¼‰ãƒˆãƒ¼ã‚¯ãƒ³ã®IDã‚’ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã§å¤‰æ›ã—ã¦å–å¾—
        ]

        """ãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆ
        prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        max_new_tokens: ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã§ãã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
        eos_token_id: çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³
        do_sample: ç”Ÿæˆæ™‚ã«ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å°å…¥ã™ã‚‹
        temperature: ãƒ©ãƒ³ãƒ€ãƒ æ€§ã®åˆ¶å¾¡, å€¤ãŒé«˜ã„ã»ã©ãƒ©ãƒ³ãƒ€ãƒ ã«ãªã‚‹(0.6ã¯ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¦ã„ã‚‹)
        top_p: ç¢ºç‡ç´¯ç©ãŒæŒ‡å®šã®å€¤ã«ãªã‚‹ã¾ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ä¸­ã‹ã‚‰æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹(éå¸¸ã«ä½ã„ç¢ºç‡ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒé¸ã°ã‚Œã‚‹ã“ã¨ã‚’é˜²ã)
        """
        outputs = self.pipeline(
            prompt, max_new_tokens=256, eos_token_id=terminators,
            do_sample=True, temperature=0.6, top_p=0.9,
        )

        # outputã«ã¯å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã©ã®æƒ…å ±ã‚‚å«ã¾ã‚Œã‚‹ã®ã§ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ã®ã¿ã‚’æŠ½å‡º
        generated_text = outputs[0]['generated_text']
        bot_response = generated_text[len(prompt):].strip()


        # botã®å¿œç­”ã‚’å¯¾è©±å±¥æ­´ã«è¿½åŠ 
        self.messages.append({"role": "assistant", "content": bot_response})
        return bot_response

print("âœ… step3: äº¤æ¸‰ãƒœãƒƒãƒˆã‚¯ãƒ©ã‚¹ã®å®šç¾©ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# %%
# =============================================
# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒœãƒƒãƒˆã®ä½œæˆã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
# =============================================
bot = NegotiationBot() # ä¸Šè¨˜ã§å®šç¾©ã—ãŸã‚¯ãƒ©ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”Ÿæˆ
bot.load_model() # load_modelã®å®Ÿè¡Œ(Hugging Face Hubã‹ã‚‰æŒ‡å®šã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰)
print("âœ… step4: ãƒœãƒƒãƒˆã®ä½œæˆã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# %%
# =============================================
# ã‚¹ãƒ†ãƒƒãƒ—5: äº¤æ¸‰ã‚·ãƒŠãƒªã‚ªã®è¨­å®š
# =============================================
item = "ã»ã¨ã‚“ã©æœªä½¿ç”¨ã®ãƒ“ãƒ³ãƒ†ãƒ¼ã‚¸é©è£½ã‚½ãƒ•ã‚¡ã€‚çŠ¶æ…‹ã¯éå¸¸ã«è‰¯ã„ã§ã™ã€‚"
seller_starting_price = 600
seller_goal = 550
bot.set_scenario(item, seller_starting_price, seller_goal)
print("âœ… ã‚¹ãƒ†ãƒƒãƒ—5: äº¤æ¸‰ã‚·ãƒŠãƒªã‚ªã®è¨­å®šãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# %%
# =============================================
# ã‚¹ãƒ†ãƒƒãƒ—6: äº¤æ¸‰ã®é–‹å§‹ï¼ˆæœ€åˆã®å¯¾è©±ï¼‰
# =============================================
user_message = f"ã“ã‚“ã«ã¡ã¯ã€ã“ã®ã‚½ãƒ•ã‚¡ã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™ã€‚ä¾¡æ ¼ã¯${seller_starting_price}ã§ã™ã­ã€‚"
print(f"ã‚ãªãŸ (è²·ã„æ‰‹): {user_message}\n")
bot_response = bot.talk(user_message)
print(f"å£²ã‚Šæ‰‹ (Llama3): {bot_response}")

# %%
# =============================================
# ã‚¹ãƒ†ãƒƒãƒ—7: äº¤æ¸‰ã‚’ç¶šã‘ã‚‹ï¼ˆå¯¾è©±ãƒ«ãƒ¼ãƒ—ï¼‰
# =============================================
your_next_offer = "ã¨ã¦ã‚‚ç´ æ•µãªã‚½ãƒ•ã‚¡ã§ã™ã­ï¼ã‚‚ã—ã‚ˆã‚ã—ã‘ã‚Œã°ã€$450ã§ãŠè­²ã‚Šã„ãŸã ãã“ã¨ã¯å¯èƒ½ã§ã—ã‚‡ã†ã‹ï¼Ÿ"
print(f"ã‚ãªãŸ (è²·ã„æ‰‹): {your_next_offer}\n")
bot_response = bot.talk(your_next_offer)
print(f"å£²ã‚Šæ‰‹ (Llama3): {bot_response}")
# %%
